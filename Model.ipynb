{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = (256,256,3)\n",
    "intermediate_dim = 64\n",
    "latent_dim = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 8, 8)\n",
      "(None, 512)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "inputs = keras.Input(shape=original_dim)\n",
    "\n",
    "# Create/Apply Conv Layers\n",
    "bn1 = layers.BatchNormalization()(inputs)\n",
    "c1 = layers.Conv2D(32, (2,2), activation='relu', padding='same')(bn1)\n",
    "mp1 = layers.MaxPooling2D((4, 4), padding='same')(c1)\n",
    "dpo1 = layers.Dropout(0.3)(mp1)\n",
    "\n",
    "bn2 = layers.BatchNormalization()(dpo1)\n",
    "c2 = layers.Conv2D(16, (4,4), activation='relu', padding='same')(bn2)\n",
    "mp2 = layers.MaxPooling2D((4, 4), padding='same')(c2)\n",
    "dpo2 = layers.Dropout(0.3)(mp2)\n",
    "\n",
    "bn3 = layers.BatchNormalization()(dpo2)\n",
    "c3 = layers.Conv2D(8, (8,8), activation='relu', padding='same')(bn3)\n",
    "mp3 = layers.MaxPooling2D((2, 2), padding='same')(c3)\n",
    "dpo3 = layers.Dropout(0.3)(mp3)\n",
    "print(dpo3.shape)\n",
    "\n",
    "# Flatten the layer\n",
    "flat = layers.Flatten()(dpo3)\n",
    "print(flat.shape)\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(flat)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "reshape = layers.Reshape((8,8,8))(x) # undo flatten\n",
    "# Deconvolution\n",
    "bn4 = layers.BatchNormalization()(reshape)\n",
    "c4 = layers.Conv2D(8, (8,8), activation='relu', padding='same')(bn4)\n",
    "us4 = layers.UpSampling2D((4, 4))(c4)\n",
    "dpo4 = layers.Dropout(0.3)(us4)\n",
    "\n",
    "bn5 = layers.BatchNormalization()(dpo4)\n",
    "c5 = layers.Conv2D(16, (4,4), activation='relu', padding='same')(bn5)\n",
    "us5 = layers.UpSampling2D((2, 2))(c5)\n",
    "dpo5 = layers.Dropout(0.3)(us5)\n",
    "\n",
    "bn6 = layers.BatchNormalization()(dpo5)\n",
    "c6 = layers.Conv2D(32, (2,2), activation='relu', padding='same')(bn6)\n",
    "us6 = layers.UpSampling2D((4, 4))(c6)\n",
    "dpo6 = layers.Dropout(0.3)(us6)\n",
    "\n",
    "# bn7 = layers.BatchNormalization()(dpo6)\n",
    "# c7 = layers.Conv2D(32, (2,2), activation='relu', padding='same')(bn7)\n",
    "# us7 = layers.UpSampling2D((4, 4))(c7)\n",
    "# dpo7 = layers.Dropout(0.3)(us7)\n",
    "\n",
    "# bn8 = layers.BatchNormalization()(dpo7)\n",
    "# c8 = layers.Conv2D(32, (2,2), activation='relu', padding='same')(bn8)\n",
    "# us8 = layers.UpSampling2D((4, 4))(c8)\n",
    "# dpo8 = layers.Dropout(0.3)(us8)\n",
    "\n",
    "outputs = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same')(dpo6)\n",
    "\n",
    "\n",
    "# outputs = layers.Dense(original_dim[1], activation='sigmoid')()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 40),         55060       ['input_5[0][0]']                \n",
      "                                 (None, 40),                                                      \n",
      "                                 (None, 40)]                                                      \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 256, 256, 3)  45147       ['encoder[0][2]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 256, 256, 3)  12         ['input_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 256, 256, 32  416         ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 64, 64, 32)  0           ['conv2d_28[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 64, 64, 32)   0           ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 64, 32)  128         ['dropout_24[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 64, 64, 16)   8208        ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 16, 16, 16)  0           ['conv2d_29[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 16, 16, 16)   0           ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 16, 16, 16)  64          ['dropout_25[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 8)    8200        ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 8, 8, 8)     0           ['conv2d_30[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 8, 8, 8)      0           ['max_pooling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 512)          0           ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 64)           32832       ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 40)           2600        ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 40)           2600        ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 40)          0           ['dense_22[0][0]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.square_3 (TFOpLambda)  (None, 40)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)         (None, 256, 256, 3)  0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_9 (TFOpLa  (None, 256, 256, 3)  0          ['decoder[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, 40)          0           ['tf.__operators__.add_6[0][0]', \n",
      " )                                                                'tf.math.square_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp_3 (TFOpLambda)     (None, 40)           0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " tf.keras.backend.binary_crosse  (None, 256, 256, 3)  0          ['tf.cast_3[0][0]',              \n",
      " ntropy_3 (TFOpLambda)                                            'tf.convert_to_tensor_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (None, 40)          0           ['tf.math.subtract_6[0][0]',     \n",
      " )                                                                'tf.math.exp_3[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_6 (TFOpLam  (None, 256, 256)    0           ['tf.keras.backend.binary_crossen\n",
      " bda)                                                            tropy_3[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  (None,)             0           ['tf.math.subtract_7[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 256, 256)    0           ['tf.math.reduce_mean_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_3[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 256, 256)    0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_7 (TFOpLam  ()                  0           ['tf.__operators__.add_7[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_3 (AddLoss)           ()                   0           ['tf.math.reduce_mean_7[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,207\n",
      "Trainable params: 100,041\n",
      "Non-trainable params: 166\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the loss function\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim[1]\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "print(vae.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m crop \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(w, h)\n\u001b[0;32m     11\u001b[0m crop_dim \u001b[39m=\u001b[39m (w\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m crop\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, h\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m crop\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, w\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m crop\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, h\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m crop\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mcrop(crop_dim)\n\u001b[0;32m     13\u001b[0m image\u001b[39m.\u001b[39mthumbnail(original_dim[:\u001b[39m2\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[39m# image.show()\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# image_array = np.asarray(image)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# print(image_array.shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\PIL\\Image.py:1211\u001b[0m, in \u001b[0;36mImage.crop\u001b[1;34m(self, box)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39melif\u001b[39;00m box[\u001b[39m3\u001b[39m] \u001b[39m<\u001b[39m box[\u001b[39m1\u001b[39m]:\n\u001b[0;32m   1209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCoordinate \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is less than \u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_crop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim, box))\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\PIL\\ImageFile.py:260\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m         )\n\u001b[0;32m    259\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 260\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    262\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "subreddits = os.listdir(\"D:\\MPH-2022-Data\")\n",
    "for subreddit in subreddits:\n",
    "    subreddit_folder = os.path.join(\"D:\\MPH-2022-Data\", subreddit)\n",
    "    image_paths = [os.path.join(subreddit_folder, filename) for filename in os.listdir(subreddit_folder) if \".csv\" not in filename]\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        w = image.width\n",
    "        h = image.height\n",
    "        crop = min(w, h)\n",
    "        crop_dim = (w//2 - crop//2, h//2 - crop//2, w//2 + crop//2, h//2 + crop//2)\n",
    "        image = image.crop(crop_dim)\n",
    "        image.thumbnail(original_dim[:2])\n",
    "        # image.show()\n",
    "        # image_array = np.asarray(image)\n",
    "        # print(image_array.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class Custom_Generator(Sequence):\n",
    "\n",
    "    #initialise generator\n",
    "    def __init__(self, data_folder_path, batch_size) :\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.batch_size = batch_size\n",
    "        self.total_number_of_files = 0\n",
    "        self.number_of_files = {}\n",
    "        for subreddit_folder in os.listdir(data_folder_path):\n",
    "            subreddit_folder_path = os.path.join(data_folder_path, subreddit_folder)\n",
    "            # print(subreddit_folder)\n",
    "            try:\n",
    "                data = pd.read_csv(os.path.join(subreddit_folder_path, f\"{subreddit_folder}.csv\"), delimiter=\";\")\n",
    "            except:\n",
    "                continue\n",
    "            data = data[data[\"Type\"] == \"image\"]\n",
    "            self.number_of_files[subreddit_folder] = len(data)\n",
    "        self.total_number_of_files = sum(self.number_of_files.values())\n",
    "    \n",
    "    #returns number of data batches this generator will return\n",
    "    def __len__(self) :\n",
    "        return np.ceil(self.total_number_of_files / float(self.batch_size)).astype(np.int)\n",
    "  \n",
    "    def preprocess_image(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        w = image.width\n",
    "        h = image.height\n",
    "        crop = min(w, h)\n",
    "        crop_dim = (w//2 - crop//2, h//2 - crop//2, w//2 + crop//2, h//2 + crop//2)\n",
    "        image = image.crop(crop_dim)\n",
    "        image.thumbnail(original_dim[:2])    \n",
    "        image_array = np.asarray(image)\n",
    "        # print(image_array.shape)\n",
    "        if len(image_array.shape) == 4: \n",
    "            return image_array[:,:,:,0]\n",
    "        else: \n",
    "            return image_array\n",
    "\n",
    "    #returns a single batch \n",
    "    def __getitem__(self, idx) :\n",
    "        subreddit_folders = self.number_of_files.keys()\n",
    "        images = []\n",
    "        idx = 0\n",
    "        for subreddit_folder in subreddit_folders:\n",
    "            # Get the image paths for this subreddit folder\n",
    "            subreddit_folder_path = os.path.join(self.data_folder_path, subreddit_folder)\n",
    "            data = pd.read_csv(os.path.join(subreddit_folder_path, f\"{subreddit_folder}.csv\"), delimiter=\";\")\n",
    "            data = data[data[\"Type\"] == \"image\"]\n",
    "            image_paths = data[\"Content File\"]\n",
    "            # If we can't add all of them, add while we can\n",
    "            if len(images) + self.number_of_files[subreddit_folder] > self.batch_size:\n",
    "                idx = 0\n",
    "                while len(images) < self.batch_size:\n",
    "                    images.append(self.preprocess_image(image_paths[idx]))\n",
    "                    idx += 1\n",
    "            # Otherwise, add them all\n",
    "            else:\n",
    "                images.extend([self.preprocess_image(image_path) for image_path in image_paths])\n",
    "\n",
    "        return (np.array(images), np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_31612\\1190475767.py:25: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.ceil(self.total_number_of_files / float(self.batch_size)).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  410/24111 [..............................] - ETA: 3:39:51 - loss: -75894544.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mrun_functions_eagerly(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m vae\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      4\u001b[0m     Custom_Generator(\u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mMPH-2022-Data\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:892\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_functions_eagerly:\n\u001b[0;32m    891\u001b[0m   \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, tf_function_call\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meager\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    894\u001b[0m \u001b[39m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[39m# place.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\keras\\engine\\training.py:1160\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1159\u001b[0m     \u001b[39m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\keras\\engine\\training.py:1145\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile:\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1145\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[0;32m   1146\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mrun(run_step, args\u001b[39m=\u001b[39m(data,))\n\u001b[0;32m   1147\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\Development-Tools\\Python-Environments\\MPH-2022-Env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3010\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3011\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3012\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[0;32m   3013\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[0;32m   3014\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "history = vae.fit(\n",
    "    Custom_Generator(\"D:\\MPH-2022-Data\", 1),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('MPH-2022-Env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e68ef567277801e40ba869e3328ed3ebeff6b1218c8a32ed665bfe3f06aa4552"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
